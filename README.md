# EXP-2-PROMPT-ENGINEERING-

## Aim: 
Comparative Analysis of different types of Prompting patterns and explain with Various Test Scenarios

Experiment:
Test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios. 
Analyze the quality, accuracy, and depth of the generated responses.


## Algorithm:
<img width="968" height="291" alt="image" src="https://github.com/user-attachments/assets/c2c53d88-7b87-451f-a5d9-cb23611022fe" />
<img width="902" height="730" alt="image" src="https://github.com/user-attachments/assets/cd83179e-ab3f-48bc-a503-773c758b0f9f" />
# Scenario A: Broad / Unstructured Prompt
# Broad/uncleared prompt
<img width="991" height="699" alt="image" src="https://github.com/user-attachments/assets/1332543f-e0f2-4c09-a822-c88dac106f23" />
# clearer/basic prompt
# Scenario B: Complex Reasoning (Math/Logic)
# Broad/uncleared prompt
<img width="989" height="246" alt="image" src="https://github.com/user-attachments/assets/c3d9c963-d3e6-4aa3-bdbd-f1bf12039a04" />
# clearer/basic prompt
# Scenario C: Creative Writing
# Broad/uncleared prompt
<img width="887" height="797" alt="image" src="https://github.com/user-attachments/assets/b14ce322-7655-485c-9d6f-aea2d017e131" />
# clearer/basic prompt
# Scenario D: Knowledge-based Query
# Broad/uncleared prompt

# clearer/basic prompt


## Output

## Result
